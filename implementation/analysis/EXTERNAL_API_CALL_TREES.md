# External API Services Call Tree Analysis
## Dashboard â†’ Admin API â†’ External Data Sources

**Document Version**: 1.1  
**Created**: 2025-10-13  
**Last Updated**: 2025-10-13 (Epic 13 - data-api separation)  
**Purpose**: Detailed call trees for all external API services showing complete data flow patterns

> **Epic 13 Update**: External API queries now routed through **data-api:8006** instead of admin-api:8003
> - Sports data queries: `data-api:8006/api/v1/sports/*`
> - Historical data queries moved to data-api for better scalability
> - admin-api now focuses solely on system monitoring

---

## ğŸ”— Related Documentation

- [HA Event Call Tree](./HA_EVENT_CALL_TREE.md)
- [Architecture Overview](../../docs/architecture.md)
- [Tech Stack](../../docs/architecture/tech-stack.md)
- [Source Tree Structure](../../docs/architecture/source-tree.md)
- [Data Models](../../docs/architecture/data-models.md)
- [API Documentation](../../docs/API_DOCUMENTATION.md)

---

## ğŸ” Quick Reference

| Question | Answer | Section |
|----------|--------|---------|
| How many external services? | 6 services | [Service Catalog](#-service-catalog) |
| What are the two patterns? | Push (continuous) & Pull (on-demand) | [Overview](#-overview) |
| Which services push to InfluxDB? | Air Quality, Carbon, Electricity, Smart Meter, Calendar | [Pattern A](#pattern-a-continuous-push-to-influxdb) |
| Which services use direct queries? | Sports Data | [Pattern B](#pattern-b-on-demand-pull-queries) |
| How often do services fetch data? | 5-60 minutes (varies by service) | [Service Details](#-service-specific-call-trees) |
| Are caching strategies used? | Yes, all services implement caching | [Caching](#-caching-strategies) |
| How to query external data? | Via **data-api** endpoints (Epic 13) | [API Layer](#phase-3-data-api-gateway-epic-13) |

---

## ğŸ”Œ Service Ports Reference

| Service | Port | Purpose | Data Pattern | Fetch Interval | Required |
|---------|------|---------|--------------|----------------|----------|
| **data-api** | **8006** | **Feature data hub (queries)** | **API Gateway** | **Per request** | **Yes** |
| admin-api | 8003 | System monitoring & control | API Gateway | Per request | Yes |
| sports-data | 8005 | NFL/NHL game data (cache) | Pull (on-demand) | Per request | Optional |
| air-quality-service | 8012 | AQI from AirNow API | Push (continuous) | 60 min | Optional |
| carbon-intensity-service | 8010 | Grid carbon from WattTime | Push (continuous) | 15 min | Optional |
| electricity-pricing-service | 8011 | Real-time pricing | Push (continuous) | 60 min | Optional |
| calendar-service | 8013 | Google Calendar occupancy | Push (continuous) | 15 min | Optional |
| smart-meter-service | 8014 | Power consumption | Push (continuous) | 5 min | Optional |

**Note**: As of Epic 13, data-api handles all feature queries (sports, events, devices), while admin-api handles system monitoring.

---

## ğŸ“Š Overview

External API services integrate third-party data sources into the Home Assistant Ingestor system. These services follow two distinct patterns based on their data characteristics and usage patterns.

### Two Data Flow Patterns

#### Pattern A: Continuous Push to InfluxDB
**Services**: Air Quality, Carbon Intensity, Electricity Pricing, Smart Meter, Calendar

```
External API â†’ Service (periodic fetch) â†’ InfluxDB â†’ Admin API â†’ Dashboard
```

**Characteristics**:
- **Continuous Operation**: Services run background loops
- **Periodic Fetching**: Data fetched at regular intervals (5-60 min)
- **InfluxDB Storage**: Data persisted for historical queries
- **Caching**: Short-term cache for API failures
- **Use Case**: Time-series data, trending, historical analysis

#### Pattern B: On-Demand Pull Queries
**Services**: Sports Data

```
Dashboard â†’ Admin API â†’ Service â†’ External API (if cache miss) â†’ Response
```

**Characteristics**:
- **Request-Driven**: Data fetched only when requested
- **Short-TTL Cache**: 15-second cache for live games, 5-minute for upcoming
- **No InfluxDB Storage**: Transient data, not persisted
- **Low API Usage**: Optimized to stay within free tier limits
- **Use Case**: Real-time data that changes frequently

---

### Architecture Overview Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      External APIs                          â”‚
â”‚  AirNow â”‚ WattTime â”‚ Awattar â”‚ ESPN â”‚ Google â”‚ Smart Meter â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚         â”‚         â”‚        â”‚       â”‚          â”‚
     â”‚ Pattern A: Continuous Push  â”‚       â”‚ Pattern B: Pull  â”‚
     â”‚ (60min) â”‚ (15min) â”‚ (60min)â”‚(5min) â”‚ (15min)  â”‚(on-demand)
     â–¼         â–¼         â–¼        â–¼       â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    External API Services           â”‚   â”‚   Sports Data       â”‚
â”‚  (Ports: 8010-8014)               â”‚   â”‚   Service (8005)    â”‚
â”‚  - Periodic fetching               â”‚   â”‚   - On-demand only  â”‚
â”‚  - Background loops                â”‚   â”‚   - Cache-first     â”‚
â”‚  - Error handling                  â”‚   â”‚   - No persistence  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                           â”‚
         â”‚ Write continuously                        â”‚ No write
         â–¼                                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚      InfluxDB (Port 8086)         â”‚              â”‚
â”‚  Measurements:                     â”‚              â”‚
â”‚   - air_quality                    â”‚              â”‚
â”‚   - carbon_intensity               â”‚              â”‚
â”‚   - electricity_pricing            â”‚              â”‚
â”‚   - smart_meter                    â”‚              â”‚
â”‚   - occupancy_prediction           â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
         â”‚ Flux queries                             â”‚ HTTP GET
         â–¼                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Admin API Service (Port 8003)                        â”‚
â”‚  - Gateway for all external data                             â”‚
â”‚  - Query InfluxDB for historical data                        â”‚
â”‚  - Proxy requests to sports-data service                     â”‚
â”‚  - Aggregation and formatting                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Health Dashboard (Port 3000)                         â”‚
â”‚  Tabs consuming external data:                               â”‚
â”‚   - Overview: All metrics summary                            â”‚
â”‚   - Sports: Live games (sports-data)                         â”‚
â”‚   - Data Sources: Air quality, carbon, pricing, smart meter  â”‚
â”‚   - Analytics: Historical trends from InfluxDB               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Sequence Diagram (Mermaid)

```mermaid
sequenceDiagram
    participant ExtAPI as External APIs<br/>(AirNow, WattTime, etc.)
    participant Service as External API Service<br/>(Ports 8010-8014)
    participant DB as InfluxDB<br/>(Port 8086)
    participant AdminAPI as Admin API<br/>(Port 8003)
    participant UI as Dashboard<br/>(Port 3000)
    participant SportsAPI as ESPN API
    participant SportsService as Sports Data Service<br/>(Port 8005)
    
    Note over Service,DB: Pattern A: Continuous Push (Air Quality, Carbon, etc.)
    
    loop Every 5-60 minutes
        Service->>ExtAPI: GET /api/data (API key)
        ExtAPI-->>Service: JSON response
        Service->>Service: Parse & validate
        Service->>DB: Write Point (time-series)
        DB-->>Service: Write confirmation
        Service->>Service: Update cache
    end
    
    Note over UI,DB: Dashboard Queries Historical Data
    
    UI->>AdminAPI: GET /api/data-sources/air-quality
    AdminAPI->>DB: Flux query (last 24h)
    DB-->>AdminAPI: Time-series data
    AdminAPI->>AdminAPI: Format response
    AdminAPI-->>UI: JSON response
    UI->>UI: Render charts
    
    Note over UI,SportsService: Pattern B: On-Demand Pull (Sports Data)
    
    UI->>AdminAPI: GET /api/sports/live-games?teams=sf,dal
    AdminAPI->>SportsService: Proxy request
    
    alt Cache Hit
        SportsService->>SportsService: Return cached data
        SportsService-->>AdminAPI: JSON (from cache)
    else Cache Miss
        SportsService->>SportsAPI: GET /scoreboard (no auth)
        SportsAPI-->>SportsService: JSON response
        SportsService->>SportsService: Filter by teams
        SportsService->>SportsService: Cache (15s TTL)
        SportsService-->>AdminAPI: JSON (filtered)
    end
    
    AdminAPI-->>UI: JSON response
    UI->>UI: Render live scores
```

---

## ğŸ—‚ï¸ Service Catalog

### 1. Sports Data Service (Port 8005)
- **Provider**: ESPN API (Free, no API key)
- **Sports**: NFL, NHL
- **Pattern**: Pull (on-demand)
- **Features**: Team filtering, live scores, upcoming games
- **Caching**: 15s (live), 5min (upcoming)
- **Storage**: None (transient)

### 2. Air Quality Service (Port 8012)
- **Provider**: AirNow API
- **Data**: AQI, PM2.5, PM10, Ozone
- **Pattern**: Push (continuous)
- **Fetch Interval**: 60 minutes
- **Measurement**: `air_quality`
- **Retention**: 1 year

### 3. Carbon Intensity Service (Port 8010)
- **Provider**: WattTime API
- **Data**: Grid carbon intensity, renewable percentage
- **Pattern**: Push (continuous)
- **Fetch Interval**: 15 minutes
- **Measurement**: `carbon_intensity`
- **Retention**: 1 year

### 4. Electricity Pricing Service (Port 8011)
- **Provider**: Awattar API (configurable)
- **Data**: Real-time pricing, peak periods, forecasts
- **Pattern**: Push (continuous)
- **Fetch Interval**: 60 minutes
- **Measurement**: `electricity_pricing`
- **Retention**: 1 year

### 5. Smart Meter Service (Port 8014)
- **Provider**: Generic adapter (configurable)
- **Data**: Whole-home power, circuit-level consumption
- **Pattern**: Push (continuous)
- **Fetch Interval**: 5 minutes
- **Measurement**: `smart_meter`, `smart_meter_circuit`
- **Retention**: 1 year

### 6. Calendar Service (Port 8013)
- **Provider**: Google Calendar API
- **Data**: Occupancy prediction, WFH status
- **Pattern**: Push (continuous)
- **Fetch Interval**: 15 minutes
- **Measurement**: `occupancy_prediction`
- **Retention**: 90 days

---

## ğŸ”„ Detailed Call Trees

### Pattern A: Continuous Push to InfluxDB

This pattern applies to: **Air Quality**, **Carbon Intensity**, **Electricity Pricing**, **Smart Meter**, **Calendar**

---

## ğŸ“ˆ Service-Specific Call Trees

### Service 1: Air Quality Service (Port 8012)

#### Phase 1: Service Initialization

**File**: `services/air-quality-service/src/main.py`

```python
main()
â””â”€â–º logger.info("Starting Air Quality Service...")
    â””â”€â–º AirQualityService.__init__()
        â”œâ”€â–º Load environment variables
        â”‚   â”œâ”€â–º AIRNOW_API_KEY (required)
        â”‚   â”œâ”€â–º LATITUDE, LONGITUDE (location)
        â”‚   â”œâ”€â–º INFLUXDB_TOKEN, INFLUXDB_URL
        â”‚   â””â”€â–º Validate required vars
        â”‚
        â”œâ”€â–º Configure service parameters
        â”‚   â”œâ”€â–º base_url = "https://www.airnowapi.org/aq/observation/latLong/current/"
        â”‚   â”œâ”€â–º fetch_interval = 3600 seconds (1 hour)
        â”‚   â””â”€â–º cache_duration = 60 minutes
        â”‚
        â”œâ”€â–º Initialize components
        â”‚   â”œâ”€â–º cached_data = None
        â”‚   â”œâ”€â–º last_fetch_time = None
        â”‚   â””â”€â–º health_handler = HealthCheckHandler()
        â”‚
        â””â”€â–º startup()
            â”œâ”€â–º aiohttp.ClientSession(timeout=10s)
            â”œâ”€â–º InfluxDBClient3(host, token, database, org)
            â””â”€â–º logger.info("Air Quality Service initialized")
```

**Initialization Checklist**:
- âœ… API key validated
- âœ… Location configured (lat/lon)
- âœ… HTTP session created with timeout
- âœ… InfluxDB client connected
- âœ… Health check endpoint ready

---

#### Phase 2: Continuous Data Collection Loop

**File**: `services/air-quality-service/src/main.py`

```python
run_continuous()
â””â”€â–º while True:  # Infinite loop
    â”œâ”€â–º try:
    â”‚   â”œâ”€â–º fetch_air_quality()
    â”‚   â”‚   â”œâ”€â–º log_with_context("Fetching AQI for location...")
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€â–º session.get(base_url, params={
    â”‚   â”‚   â”‚     "latitude": self.latitude,
    â”‚   â”‚   â”‚     "longitude": self.longitude,
    â”‚   â”‚   â”‚     "format": "application/json",
    â”‚   â”‚   â”‚     "API_KEY": self.api_key
    â”‚   â”‚   â”‚   })
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€â–º if response.status == 200:
    â”‚   â”‚   â”‚   â”œâ”€â–º raw_data = await response.json()
    â”‚   â”‚   â”‚   â”‚   # Example response:
    â”‚   â”‚   â”‚   â”‚   # [
    â”‚   â”‚   â”‚   â”‚   #   {"AQI": 45, "ParameterName": "PM2.5", "Category": {"Name": "Good"}},
    â”‚   â”‚   â”‚   â”‚   #   {"AQI": 38, "ParameterName": "OZONE", "Category": {"Name": "Good"}}
    â”‚   â”‚   â”‚   â”‚   # ]
    â”‚   â”‚   â”‚   â”‚
    â”‚   â”‚   â”‚   â”œâ”€â–º Parse response into unified structure:
    â”‚   â”‚   â”‚   â”‚   data = {
    â”‚   â”‚   â”‚   â”‚       'aqi': max(all AQI values),  # Worst parameter
    â”‚   â”‚   â”‚   â”‚       'category': 'Good' | 'Moderate' | 'Unhealthy',
    â”‚   â”‚   â”‚   â”‚       'parameter': 'PM2.5' | 'PM10' | 'OZONE',
    â”‚   â”‚   â”‚   â”‚       'pm25': specific PM2.5 AQI,
    â”‚   â”‚   â”‚   â”‚       'pm10': specific PM10 AQI,
    â”‚   â”‚   â”‚   â”‚       'ozone': specific Ozone AQI,
    â”‚   â”‚   â”‚   â”‚       'timestamp': datetime.now()
    â”‚   â”‚   â”‚   â”‚   }
    â”‚   â”‚   â”‚   â”‚
    â”‚   â”‚   â”‚   â”œâ”€â–º if category changed from last_category:
    â”‚   â”‚   â”‚   â”‚   â””â”€â–º logger.warning("AQI category changed")
    â”‚   â”‚   â”‚   â”‚
    â”‚   â”‚   â”‚   â”œâ”€â–º Update cache
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â–º self.cached_data = data
    â”‚   â”‚   â”‚   â”‚   â””â”€â–º self.last_fetch_time = now
    â”‚   â”‚   â”‚   â”‚
    â”‚   â”‚   â”‚   â”œâ”€â–º Update health metrics
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â–º health_handler.last_successful_fetch = now
    â”‚   â”‚   â”‚   â”‚   â””â”€â–º health_handler.total_fetches += 1
    â”‚   â”‚   â”‚   â”‚
    â”‚   â”‚   â”‚   â””â”€â–º return data
    â”‚   â”‚   â”‚
    â”‚   â”‚   â””â”€â–º else:  # API error
    â”‚   â”‚       â”œâ”€â–º logger.error("AirNow API returned status {status}")
    â”‚   â”‚       â”œâ”€â–º health_handler.failed_fetches += 1
    â”‚   â”‚       â””â”€â–º return self.cached_data  # Fallback
    â”‚   â”‚
    â”‚   â”œâ”€â–º if data:
    â”‚   â”‚   â””â”€â–º store_in_influxdb(data)
    â”‚   â”‚       â”œâ”€â–º point = Point("air_quality")
    â”‚   â”‚       â”‚   .tag("location", "36.1699,-115.1398")
    â”‚   â”‚       â”‚   .tag("category", "Good")
    â”‚   â”‚       â”‚   .tag("parameter", "PM2.5")
    â”‚   â”‚       â”‚   .field("aqi", 45)
    â”‚   â”‚       â”‚   .field("pm25", 45)
    â”‚   â”‚       â”‚   .field("pm10", 38)
    â”‚   â”‚       â”‚   .field("ozone", 32)
    â”‚   â”‚       â”‚   .time(timestamp)
    â”‚   â”‚       â”‚
    â”‚   â”‚       â”œâ”€â–º influxdb_client.write(point)
    â”‚   â”‚       â””â”€â–º logger.info("AQI data written to InfluxDB")
    â”‚   â”‚
    â”‚   â””â”€â–º await asyncio.sleep(3600)  # Wait 1 hour
    â”‚
    â””â”€â–º except Exception as e:
        â”œâ”€â–º log_error_with_context("Error in continuous loop")
        â””â”€â–º await asyncio.sleep(300)  # Wait 5 min before retry
```

**Loop Characteristics**:
- **Interval**: 3600 seconds (1 hour)
- **Error Recovery**: 5-minute retry delay on failure
- **Fallback**: Returns cached data if API fails
- **Monitoring**: Health metrics updated on each attempt

---

#### Phase 3: Data Retrieval (Dashboard Query)

**Dashboard Request Flow**:

```
Dashboard (React)
â””â”€â–º apiService.getAirQuality()
    â””â”€â–º fetch('http://localhost:8003/api/data-sources/air-quality')
        â””â”€â–º Admin API: /api/data-sources/air-quality
            â””â”€â–º InfluxDBClient.query()
                â”œâ”€â–º Flux query:
                â”‚   from(bucket: "events")
                â”‚     |> range(start: -24h)
                â”‚     |> filter(fn: (r) => r._measurement == "air_quality")
                â”‚     |> filter(fn: (r) => r.location == "36.1699,-115.1398")
                â”‚     |> sort(columns: ["_time"], desc: true)
                â”‚     |> limit(n: 100)
                â”‚
                â”œâ”€â–º Parse FluxTable results
                â”‚   â””â”€â–º Extract: time, aqi, category, pm25, pm10, ozone
                â”‚
                â””â”€â–º return JSON:
                    [
                      {
                        "timestamp": "2025-10-13T10:00:00Z",
                        "aqi": 45,
                        "category": "Good",
                        "pm25": 45,
                        "pm10": 38,
                        "ozone": 32
                      },
                      ...
                    ]
```

**Response Format**:
```json
{
  "current": {
    "aqi": 45,
    "category": "Good",
    "primary_pollutant": "PM2.5",
    "timestamp": "2025-10-13T10:00:00Z"
  },
  "history_24h": [
    {"timestamp": "2025-10-13T10:00:00Z", "aqi": 45},
    {"timestamp": "2025-10-13T09:00:00Z", "aqi": 42},
    ...
  ],
  "statistics": {
    "min": 38,
    "max": 52,
    "average": 44.5
  }
}
```

---

### Service 2: Carbon Intensity Service (Port 8010)

**Similar structure to Air Quality, key differences**:

#### Data Fetch Call Tree

**File**: `services/carbon-intensity-service/src/main.py`

```python
fetch_carbon_intensity()
â””â”€â–º url = f"{base_url}/forecast"  # WattTime V3 API
    â”œâ”€â–º headers = {"Authorization": f"Bearer {api_token}"}
    â”œâ”€â–º params = {"region": "CAISO_NORTH"}
    â”‚
    â”œâ”€â–º session.get(url, headers=headers, params=params)
    â”‚
    â””â”€â–º if response.status == 200:
        â”œâ”€â–º raw_data = await response.json()
        â”‚   # WattTime response structure:
        â”‚   # {
        â”‚   #   "moer": 850,  # Marginal emissions rate (gCO2/kWh)
        â”‚   #   "renewable_pct": 35.2,
        â”‚   #   "fossil_pct": 64.8,
        â”‚   #   "forecast": [
        â”‚   #     {"value": 820, "timestamp": "2025-10-13T11:00:00Z"},
        â”‚   #     {"value": 780, "timestamp": "2025-10-13T12:00:00Z"},
        â”‚   #     ...
        â”‚   #   ]
        â”‚   # }
        â”‚
        â”œâ”€â–º Parse into structured format:
        â”‚   data = {
        â”‚       'carbon_intensity': 850,  # gCO2/kWh
        â”‚       'renewable_percentage': 35.2,
        â”‚       'fossil_percentage': 64.8,
        â”‚       'forecast_1h': 820,  # Next hour forecast
        â”‚       'forecast_24h': 650,  # 24 hours ahead
        â”‚       'timestamp': datetime.now()
        â”‚   }
        â”‚
        â”œâ”€â–º Update cache
        â”œâ”€â–º Update health metrics
        â””â”€â–º return data
```

**InfluxDB Write Structure**:
```python
Point("carbon_intensity")
    .tag("region", "CAISO_NORTH")
    .tag("grid_operator", "CAISO")
    .field("carbon_intensity_gco2_kwh", 850.0)
    .field("renewable_percentage", 35.2)
    .field("fossil_percentage", 64.8)
    .field("forecast_1h", 820.0)
    .field("forecast_24h", 650.0)
    .time(timestamp)
```

**Key Differences from Air Quality**:
- âœ… Requires OAuth token (vs API key)
- âœ… Includes forecast data (1h, 24h ahead)
- âœ… Faster interval: 15 minutes (vs 60 minutes)
- âœ… Regional data (grid-specific)

---

### Service 3: Electricity Pricing Service (Port 8011)

#### Provider Adapter Pattern

**File**: `services/electricity-pricing-service/src/main.py`

```python
ElectricityPricingService.__init__()
â””â”€â–º _get_provider()
    â”œâ”€â–º provider_name = os.getenv('PRICING_PROVIDER', 'awattar')
    â”‚
    â””â”€â–º providers = {
        'awattar': AwattarProvider(),
        # Future: 'octopus': OctopusProvider(),
        # Future: 'tibber': TibberProvider()
    }
    â””â”€â–º return providers.get(provider_name)
```

#### Pricing Fetch Call Tree

**File**: `services/electricity-pricing-service/src/providers/awattar.py`

```python
AwattarProvider.fetch_pricing(session)
â””â”€â–º url = "https://api.awattar.de/v1/marketdata"
    â”œâ”€â–º params = {
    â”‚     "start": today_midnight_timestamp,
    â”‚     "end": tomorrow_midnight_timestamp
    â”‚   }
    â”‚
    â”œâ”€â–º session.get(url, params=params)  # No auth required
    â”‚
    â””â”€â–º if response.status == 200:
        â”œâ”€â–º raw_data = await response.json()
        â”‚   # Awattar response:
        â”‚   # {
        â”‚   #   "data": [
        â”‚   #     {
        â”‚   #       "start_timestamp": 1697155200000,  # Unix timestamp (ms)
        â”‚   #       "end_timestamp": 1697158800000,
        â”‚   #       "marketprice": 85.23,  # EUR/MWh
        â”‚   #       "unit": "Eur/MWh"
        â”‚   #     },
        â”‚   #     ...
        â”‚   #   ]
        â”‚   # }
        â”‚
        â”œâ”€â–º Process pricing data:
        â”‚   â”œâ”€â–º Convert EUR/MWh â†’ EUR/kWh (divide by 1000)
        â”‚   â”œâ”€â–º Find current hour price
        â”‚   â”œâ”€â–º Identify peak period (top 25% prices)
        â”‚   â”œâ”€â–º Find cheapest hours (bottom 4 hours)
        â”‚   â””â”€â–º Extract 24h forecast
        â”‚
        â””â”€â–º return {
            'current_price': 0.08523,  # EUR/kWh
            'currency': 'EUR',
            'peak_period': False,
            'cheapest_hours': [
                {'hour': 3, 'price': 0.05234},
                {'hour': 4, 'price': 0.05512},
                {'hour': 2, 'price': 0.05789},
                {'hour': 15, 'price': 0.06012}
            ],
            'forecast_24h': [
                {'hour': 0, 'price': 0.08123, 'timestamp': '2025-10-13T00:00:00Z'},
                {'hour': 1, 'price': 0.07845, 'timestamp': '2025-10-13T01:00:00Z'},
                ...
            ],
            'timestamp': datetime.now(),
            'provider': 'awattar'
        }
```

**Special Endpoint**: `/cheapest-hours`

```python
get_cheapest_hours(request)
â””â”€â–º hours_needed = int(request.query.get('hours', 4))
    â””â”€â–º if cached_data:
        â””â”€â–º return {
            'cheapest_hours': cached_data['cheapest_hours'][:hours_needed],
            'provider': 'awattar',
            'timestamp': last_fetch_time.isoformat(),
            'optimal_for': 'charging EV, running dishwasher, etc.'
        }
```

**Use Case**: Smart home automation can schedule energy-intensive tasks during cheapest hours.

---

### Service 4: Smart Meter Service (Port 8014)

#### Multi-Level Data Collection

**File**: `services/smart-meter-service/src/main.py`

```python
fetch_consumption()
â””â”€â–º Generic implementation (adapter pattern for various meters)
    â”œâ”€â–º Whole-home consumption:
    â”‚   data = {
    â”‚       'total_power_w': 2450.0,  # Current total power
    â”‚       'daily_kwh': 18.5,  # Cumulative daily energy
    â”‚       'timestamp': datetime.now()
    â”‚   }
    â”‚
    â”œâ”€â–º Circuit-level breakdown:
    â”‚   data['circuits'] = [
    â”‚       {'name': 'HVAC', 'power_w': 1200.0, 'percentage': 49.0},
    â”‚       {'name': 'Kitchen', 'power_w': 450.0, 'percentage': 18.4},
    â”‚       {'name': 'Living Room', 'power_w': 300.0, 'percentage': 12.2},
    â”‚       {'name': 'Office', 'power_w': 250.0, 'percentage': 10.2},
    â”‚       {'name': 'Bedrooms', 'power_w': 150.0, 'percentage': 6.1},
    â”‚       {'name': 'Other', 'power_w': 100.0, 'percentage': 4.1}
    â”‚   ]
    â”‚
    â”œâ”€â–º Phantom load detection:
    â”‚   if current_hour == 3:  # 3 AM baseline
    â”‚       â””â”€â–º if total_power_w > 200:
    â”‚           â””â”€â–º logger.warning("High phantom load: {power}W at 3am")
    â”‚
    â”œâ”€â–º High consumption alert:
    â”‚   if total_power_w > 10000:  # 10 kW threshold
    â”‚       â””â”€â–º logger.warning("High power consumption: {power}W")
    â”‚
    â””â”€â–º return data
```

**InfluxDB Dual-Measurement Write**:

```python
store_in_influxdb(data)
â”œâ”€â–º # Whole-home measurement
â”‚   Point("smart_meter")
â”‚       .tag("meter_type", "generic")
â”‚       .field("total_power_w", 2450.0)
â”‚       .field("daily_kwh", 18.5)
â”‚       .time(timestamp)
â”‚
â””â”€â–º # Per-circuit measurements (6 points)
    for circuit in circuits:
        Point("smart_meter_circuit")
            .tag("circuit_name", circuit['name'])
            .field("power_w", circuit['power_w'])
            .field("percentage", circuit['percentage'])
            .time(timestamp)
```

**Query Pattern** (Admin API):

```flux
// Whole-home power
from(bucket: "events")
  |> range(start: -24h)
  |> filter(fn: (r) => r._measurement == "smart_meter")
  |> filter(fn: (r) => r._field == "total_power_w")

// Circuit breakdown (current)
from(bucket: "events")
  |> range(start: -5m)
  |> filter(fn: (r) => r._measurement == "smart_meter_circuit")
  |> last()
  |> group(columns: ["circuit_name"])
```

**Dashboard Visualization**:
- Real-time power gauge (total_power_w)
- Daily energy counter (daily_kwh)
- Circuit breakdown pie chart
- 24-hour power trend line

---

### Service 5: Calendar Service (Port 8013)

#### Google Calendar Integration

**File**: `services/calendar-service/src/main.py`

```python
CalendarService.__init__()
â””â”€â–º OAuth Configuration:
    â”œâ”€â–º client_id = os.getenv('GOOGLE_CLIENT_ID')
    â”œâ”€â–º client_secret = os.getenv('GOOGLE_CLIENT_SECRET')
    â”œâ”€â–º refresh_token = os.getenv('GOOGLE_REFRESH_TOKEN')
    â””â”€â–º Validate all required

startup()
â””â”€â–º Setup OAuth credentials:
    â”œâ”€â–º credentials = Credentials(
    â”‚     token=None,
    â”‚     refresh_token=refresh_token,
    â”‚     token_uri="https://oauth2.googleapis.com/token",
    â”‚     client_id=client_id,
    â”‚     client_secret=client_secret
    â”‚   )
    â”‚
    â”œâ”€â–º if not credentials.valid:
    â”‚   â””â”€â–º credentials.refresh(Request())  # Get new access token
    â”‚
    â”œâ”€â–º calendar_service = build('calendar', 'v3', credentials=credentials)
    â”‚
    â””â”€â–º health_handler.oauth_valid = True
```

#### Occupancy Prediction Logic

```python
predict_home_status()
â””â”€â–º get_today_events()
    â”œâ”€â–º now = datetime.now().isoformat() + 'Z'
    â”œâ”€â–º end_of_day = today_23:59.isoformat() + 'Z'
    â”‚
    â”œâ”€â–º calendar_service.events().list(
    â”‚     calendarId='primary',
    â”‚     timeMin=now,
    â”‚     timeMax=end_of_day,
    â”‚     singleEvents=True,
    â”‚     orderBy='startTime'
    â”‚   ).execute()
    â”‚
    â””â”€â–º for event in events:
        â”œâ”€â–º Parse event:
        â”‚   â”œâ”€â–º summary = "Team Meeting" or "WFH Day"
        â”‚   â”œâ”€â–º location = "Office" or "Home"
        â”‚   â”œâ”€â–º start/end times
        â”‚   â””â”€â–º is_wfh = 'WFH' in summary OR 'HOME' in location
        â”‚
        â””â”€â–º Build occupancy prediction:
            â”œâ”€â–º wfh_today = any event has is_wfh=True
            â”œâ”€â–º currently_home = check if NOW is within WFH event
            â”‚
            â”œâ”€â–º Find next home arrival:
            â”‚   â”œâ”€â–º next_home_event = first future event with location='Home'
            â”‚   â”œâ”€â–º arrival_time = next_home_event.start
            â”‚   â”œâ”€â–º travel_time = 30 minutes (configurable)
            â”‚   â””â”€â–º prepare_time = arrival_time - travel_time
            â”‚       # Smart home can pre-heat/cool before arrival
            â”‚
            â””â”€â–º return {
                'currently_home': True/False,
                'wfh_today': True/False,
                'next_arrival': datetime or None,
                'prepare_time': datetime or None,  # When to start HVAC
                'hours_until_arrival': float or None,
                'confidence': 0.85 if wfh_today else 0.70,
                'timestamp': datetime.now()
            }
```

**Smart Home Integration Use Cases**:
1. **HVAC Optimization**: Start heating/cooling 30 min before arrival
2. **Security System**: Arm system when leaving, disarm before arrival
3. **Lighting**: Turn on lights before sunset arrival time
4. **Energy Management**: Run appliances during absence

**InfluxDB Measurement**:
```python
Point("occupancy_prediction")
    .tag("source", "calendar")
    .tag("user", "primary")
    .field("currently_home", True)
    .field("wfh_today", True)
    .field("confidence", 0.85)
    .field("hours_until_arrival", 0.0)  # Currently home
    .time(timestamp)
```

---

### Pattern B: On-Demand Pull Queries

### Service 6: Sports Data Service (Port 8005)

**Unique Characteristics**:
- âœ… No continuous loop (request-driven only)
- âœ… Team-based filtering (only fetch data for user's teams)
- âœ… No InfluxDB storage (transient data)
- âœ… Aggressive caching (15s live, 5min upcoming)
- âœ… Free API (ESPN, no authentication)

---

#### Phase 1: Service Initialization

**File**: `services/sports-data/src/main.py`

```python
main()
â””â”€â–º FastAPI app initialization
    â”œâ”€â–º app = FastAPI(
    â”‚     title="Sports Data Service",
    â”‚     description="NFL & NHL Sports Data API with team-based filtering",
    â”‚     version="1.0.0"
    â”‚   )
    â”‚
    â”œâ”€â–º CORS middleware:
    â”‚   â””â”€â–º allow_origins=["http://localhost:3000"]  # Dashboard
    â”‚
    â”œâ”€â–º Initialize services:
    â”‚   â”œâ”€â–º cache = CacheService()
    â”‚   â”‚   â”œâ”€â–º in-memory cache (dict)
    â”‚   â”‚   â”œâ”€â–º TTL tracking per key
    â”‚   â”‚   â””â”€â–º Statistics: hits, misses
    â”‚   â”‚
    â”‚   â””â”€â–º sports_client = SportsAPIClient(cache=cache)
    â”‚       â”œâ”€â–º ESPN base URLs
    â”‚       â”œâ”€â–º API call counters
    â”‚       â””â”€â–º Team mapping data
    â”‚
    â””â”€â–º Endpoints registered:
        â”œâ”€â–º GET /health
        â”œâ”€â–º GET /api/v1/games/live
        â”œâ”€â–º GET /api/v1/games/upcoming
        â”œâ”€â–º GET /api/v1/teams
        â”œâ”€â–º GET /api/v1/user/teams
        â”œâ”€â–º POST /api/v1/user/teams
        â””â”€â–º GET /api/v1/metrics/api-usage
```

---

#### Phase 2: Dashboard Request (Live Games)

**Complete Request Flow**:

```
User opens Sports tab in Dashboard
â””â”€â–º React Component: SportsTab.tsx
    â”œâ”€â–º useEffect() on mount
    â”œâ”€â–º user_teams = localStorage.getItem('selectedTeams')  // ['sf', 'dal']
    â”‚
    â””â”€â–º apiService.getLiveGames(user_teams)
        â””â”€â–º fetch('http://localhost:8003/api/sports/live-games?teams=sf,dal')
            
            Admin API: /api/sports/live-games
            â””â”€â–º Proxy to sports-data service:
                â””â”€â–º GET http://localhost:8005/api/v1/games/live?teams=sf,dal
                    
                    Sports Data Service: get_live_games()
                    â”œâ”€â–º Parse team_ids:
                    â”‚   â””â”€â–º teams = ['sf', 'dal']  # San Francisco, Dallas
                    â”‚
                    â””â”€â–º sports_client.get_live_games('NFL', teams)
                        â”œâ”€â–º cache_key = "live_games_nfl_sf_dal"
                        â”‚
                        â”œâ”€â–º Check cache:
                        â”‚   â””â”€â–º if cache.get(cache_key) and not expired:
                        â”‚       â”œâ”€â–º cache_stats['hits'] += 1
                        â”‚       â””â”€â–º return cached_data  # âš¡ Fast path
                        â”‚
                        â””â”€â–º Cache miss â†’ Fetch from ESPN:
                            â”œâ”€â–º cache_stats['misses'] += 1
                            â”‚
                            â”œâ”€â–º url = "https://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard"
                            â”œâ”€â–º session.get(url)  # No auth required!
                            â”‚
                            â”œâ”€â–º if response.status == 200:
                            â”‚   â”œâ”€â–º raw_data = await response.json()
                            â”‚   â”‚   # ESPN scoreboard structure:
                            â”‚   â”‚   # {
                            â”‚   â”‚   #   "leagues": [...],
                            â”‚   â”‚   #   "events": [
                            â”‚   â”‚   #     {
                            â”‚   â”‚   #       "id": "401547413",
                            â”‚   â”‚   #       "status": {
                            â”‚   â”‚   #         "type": {"state": "in", "detail": "Q2 3:24"},
                            â”‚   â”‚   #       },
                            â”‚   â”‚   #       "competitions": [{
                            â”‚   â”‚   #         "competitors": [
                            â”‚   â”‚   #           {
                            â”‚   â”‚   #             "team": {"abbreviation": "SF", "displayName": "49ers"},
                            â”‚   â”‚   #             "score": "14",
                            â”‚   â”‚   #             "homeAway": "home"
                            â”‚   â”‚   #           },
                            â”‚   â”‚   #           {
                            â”‚   â”‚   #             "team": {"abbreviation": "DAL", "displayName": "Cowboys"},
                            â”‚   â”‚   #             "score": "10",
                            â”‚   â”‚   #             "homeAway": "away"
                            â”‚   â”‚   #           }
                            â”‚   â”‚   #         ]
                            â”‚   â”‚   #       }]
                            â”‚   â”‚   #     }
                            â”‚   â”‚   #   ]
                            â”‚   â”‚   # }
                            â”‚   â”‚
                            â”‚   â”œâ”€â–º Filter events by teams:
                            â”‚   â”‚   games = []
                            â”‚   â”‚   for event in raw_data['events']:
                            â”‚   â”‚       â”œâ”€â–º Extract teams from competitors
                            â”‚   â”‚       â”œâ”€â–º team_abbrevs = ['SF', 'DAL']
                            â”‚   â”‚       â”‚
                            â”‚   â”‚       â””â”€â–º if any team in user's selected teams:
                            â”‚   â”‚           â”œâ”€â–º is_live = status.type.state == 'in'
                            â”‚   â”‚           â”‚
                            â”‚   â”‚           â””â”€â–º if is_live:
                            â”‚   â”‚               games.append({
                            â”‚   â”‚                   'id': event['id'],
                            â”‚   â”‚                   'league': 'NFL',
                            â”‚   â”‚                   'home_team': 'SF 49ers',
                            â”‚   â”‚                   'away_team': 'DAL Cowboys',
                            â”‚   â”‚                   'home_score': 14,
                            â”‚   â”‚                   'away_score': 10,
                            â”‚   â”‚                   'status': 'Q2 3:24',
                            â”‚   â”‚                   'is_live': True,
                            â”‚   â”‚                   'timestamp': now
                            â”‚   â”‚               })
                            â”‚   â”‚
                            â”‚   â”œâ”€â–º Cache filtered results:
                            â”‚   â”‚   â””â”€â–º cache.set(cache_key, games, ttl=15)  # 15 seconds
                            â”‚   â”‚
                            â”‚   â”œâ”€â–º Update API usage stats:
                            â”‚   â”‚   â”œâ”€â–º api_calls_today += 1
                            â”‚   â”‚   â””â”€â–º nfl_calls += 1
                            â”‚   â”‚
                            â”‚   â””â”€â–º return games
                            â”‚
                            â””â”€â–º return GameList(
                                games=games,
                                count=len(games),
                                filtered_by_teams=['sf', 'dal']
                            )
```

**Response to Dashboard**:
```json
{
  "games": [
    {
      "id": "401547413",
      "league": "NFL",
      "home_team": "SF 49ers",
      "away_team": "DAL Cowboys",
      "home_score": 14,
      "away_score": 10,
      "status": "Q2 3:24",
      "is_live": true,
      "timestamp": "2025-10-13T15:30:45Z"
    }
  ],
  "count": 1,
  "filtered_by_teams": ["sf", "dal"]
}
```

---

#### Phase 3: Caching Strategy

**File**: `services/sports-data/src/cache_service.py`

```python
CacheService
â”œâ”€â–º cache_data: Dict[str, CacheEntry] = {}
â”‚   # CacheEntry = {
â”‚   #   'value': Any,
â”‚   #   'expires_at': datetime,
â”‚   #   'created_at': datetime
â”‚   # }
â”‚
â”œâ”€â–º get(key: str) â†’ Optional[Any]
â”‚   â”œâ”€â–º if key not in cache_data:
â”‚   â”‚   â””â”€â–º return None  # Miss
â”‚   â”‚
â”‚   â”œâ”€â–º entry = cache_data[key]
â”‚   â”œâ”€â–º if datetime.now() > entry['expires_at']:
â”‚   â”‚   â”œâ”€â–º del cache_data[key]  # Expired
â”‚   â”‚   â””â”€â–º return None
â”‚   â”‚
â”‚   â”œâ”€â–º stats['hits'] += 1
â”‚   â””â”€â–º return entry['value']
â”‚
â””â”€â–º set(key: str, value: Any, ttl: int)
    â””â”€â–º cache_data[key] = {
        'value': value,
        'expires_at': datetime.now() + timedelta(seconds=ttl),
        'created_at': datetime.now()
    }
```

**TTL Strategy**:
- **Live games**: 15 seconds (scores change frequently)
- **Upcoming games**: 5 minutes (schedule stable)
- **Team list**: 24 hours (rarely changes)

**Cache Hit Rate** (typical):
- During live games: 80-90% hit rate (15s TTL, dashboard polls every 30s)
- Off-hours: 60-70% hit rate (fewer requests, more expiration)

---

#### Phase 4: API Usage Optimization

**Problem**: ESPN API is free but unmetered. We self-limit to stay respectful.

**Solution**: Team-based filtering + caching

```python
# WITHOUT filtering (fetches ALL games)
/api/v1/games/live  # Returns ~16 NFL games (all teams)
# Dashboard polls every 30s
# API calls per day: (60/30) * 24 * 7 = 336 calls/week

# WITH filtering (fetches only user's 2 teams)
/api/v1/games/live?teams=sf,dal  # Returns only SF and DAL games
# Cache hit rate: 85%
# API calls per day: 336 * 0.15 = ~50 calls/week
# Savings: 85% reduction
```

**API Usage Tracking**:
```python
get_api_usage()
â””â”€â–º return {
    'total_calls_today': 23,
    'nfl_calls': 15,
    'nhl_calls': 8,
    'cache_hits': 67,
    'cache_misses': 23,
    'hit_rate': 0.744,  # 74.4%
    'estimated_daily_calls': 50,
    'within_free_tier': True
}
```

---

## ğŸ¯ Caching Strategies

### Comparison of Caching Patterns

| Service | Cache Location | TTL | Fallback Behavior | Cache Key |
|---------|---------------|-----|-------------------|-----------|
| **Sports Data** | In-memory (service) | 15s-5min | No data (empty list) | `live_games_{league}_{teams}` |
| **Air Quality** | Instance variable | 60 min | Return stale cache | `cached_data` (single) |
| **Carbon Intensity** | Instance variable | 15 min | Return stale cache | `cached_data` (single) |
| **Electricity Pricing** | Instance variable | 60 min | Return stale cache | `cached_data` (single) |
| **Smart Meter** | Instance variable | None | No fallback | `cached_data` (single) |
| **Calendar** | None | None | Empty prediction | N/A |

### Cache Invalidation Rules

**Pattern A Services** (Push):
- Cache updated on successful external API fetch
- Stale cache served if API fails (graceful degradation)
- No explicit TTL (replaced on next fetch)

**Pattern B Services** (Pull):
- Cache with explicit TTL (time-based expiration)
- Cache miss triggers immediate external API call
- Empty result on cache miss + API failure

---

## ğŸ“Š Performance Characteristics

### Service Performance Metrics

| Service | Fetch Latency | Write Latency | API Rate Limit | Throughput | Memory Usage |
|---------|--------------|---------------|----------------|------------|--------------|
| **Sports Data** | 150-300ms | N/A | Self-limited | 100 req/day | 50 MB |
| **Air Quality** | 200-400ms | 50ms | 500/hour | 24 fetches/day | 30 MB |
| **Carbon Intensity** | 180-350ms | 50ms | 100/hour | 96 fetches/day | 30 MB |
| **Electricity Pricing** | 250-500ms | 80ms | Unlimited | 24 fetches/day | 35 MB |
| **Smart Meter** | 50-150ms | 60ms | N/A | 288 fetches/day | 40 MB |
| **Calendar** | 300-600ms | 50ms | Google quotas | 96 fetches/day | 45 MB |

### External API Dependencies

| External API | Authentication | Cost | Reliability | Rate Limit | Notes |
|--------------|---------------|------|-------------|------------|-------|
| **ESPN** | None | Free | 99.5% | Self-limited | Public API |
| **AirNow** | API Key | Free | 99.0% | 500/hour | Government API |
| **WattTime** | OAuth token | Paid | 98.5% | 100/hour | Subscription required |
| **Awattar** | None | Free | 99.0% | Unlimited | European markets |
| **Google Calendar** | OAuth 2.0 | Free | 99.9% | 1M/day | Requires user consent |
| **Smart Meter** | Varies | Varies | Varies | Varies | Adapter-dependent |

---

## ğŸ› ï¸ Error Handling Patterns

### Common Error Scenarios

#### 1. External API Unavailable

**Scenario**: External API returns 500/503 or times out

**Pattern A Services** (Push to InfluxDB):
```python
try:
    data = await fetch_from_external_api()
except Exception as e:
    log_error_with_context(logger, "API fetch failed", e)
    health_handler.failed_fetches += 1
    
    # Fallback: Return cached data
    if self.cached_data:
        logger.warning("Using cached data (API unavailable)")
        return self.cached_data
    
    # No cache available
    return None  # Skip InfluxDB write this cycle
```

**Pattern B Services** (On-demand):
```python
try:
    data = await fetch_from_external_api()
except Exception as e:
    log_error_with_context(logger, "API fetch failed", e)
    
    # Check cache first
    if cached_data and not expired:
        return cached_data
    
    # No cache, return error to client
    raise HTTPException(
        status_code=503,
        detail="External API unavailable and no cached data"
    )
```

---

#### 2. Authentication Failure

**OAuth Token Expired** (Carbon Intensity, Calendar):
```python
async with session.get(url, headers=headers) as response:
    if response.status == 401:  # Unauthorized
        log_error_with_context(logger, "OAuth token expired")
        
        # Attempt token refresh
        try:
            await refresh_oauth_token()
            # Retry request with new token
            return await fetch_from_external_api()
        except:
            health_handler.oauth_valid = False
            return cached_data  # Fallback
```

**API Key Invalid** (Air Quality):
```python
if response.status == 403:  # Forbidden
    log_error_with_context(logger, "Invalid API key")
    health_handler.api_key_valid = False
    
    # Critical error - cannot recover automatically
    # Alert admin via health check endpoint
    raise ValueError("API key validation failed - manual intervention required")
```

---

#### 3. Rate Limit Exceeded

**Graceful Backoff**:
```python
async def fetch_with_rate_limit():
    try:
        response = await session.get(url)
        
        if response.status == 429:  # Too Many Requests
            retry_after = int(response.headers.get('Retry-After', 60))
            logger.warning(f"Rate limited, waiting {retry_after}s")
            
            await asyncio.sleep(retry_after)
            return await fetch_with_rate_limit()  # Retry
            
    except Exception as e:
        log_error_with_context(logger, "Rate limit handling failed", e)
        return cached_data
```

---

#### 4. InfluxDB Write Failure

**Retry with Exponential Backoff**:
```python
async def store_in_influxdb_with_retry(data, max_retries=3):
    for attempt in range(max_retries):
        try:
            influxdb_client.write(point)
            logger.info("Data written to InfluxDB")
            return True
            
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # 1s, 2s, 4s
                logger.warning(f"InfluxDB write failed (attempt {attempt+1}), retrying in {wait_time}s")
                await asyncio.sleep(wait_time)
            else:
                log_error_with_context(logger, "All InfluxDB write attempts failed", e)
                # Log to file as backup
                await log_failed_write_to_file(data)
                return False
```

---

## ğŸ” Monitoring & Observability

### Health Check Endpoints

All services expose `/health` endpoint with consistent structure:

```json
{
  "status": "healthy" | "degraded" | "unhealthy",
  "service": "air-quality-service",
  "timestamp": "2025-10-13T10:30:00Z",
  "uptime_seconds": 86400,
  "metrics": {
    "total_fetches": 24,
    "successful_fetches": 23,
    "failed_fetches": 1,
    "success_rate": 0.958,
    "last_successful_fetch": "2025-10-13T10:00:00Z",
    "cache_hit_rate": 0.744
  },
  "external_api": {
    "status": "available" | "unavailable",
    "last_error": null | "error message",
    "api_key_valid": true
  },
  "influxdb": {
    "status": "connected" | "disconnected",
    "last_write": "2025-10-13T10:00:00Z"
  }
}
```

### Admin API Integration

**Aggregate Health Check**:

```
Dashboard â†’ GET /api/health/external-services
            â””â”€â–º Admin API: health_endpoints.py
                â””â”€â–º check_external_services()
                    â”œâ”€â–º for service in external_services:
                    â”‚   â”œâ”€â–º GET http://service:port/health
                    â”‚   â”œâ”€â–º response_time = measure_latency()
                    â”‚   â””â”€â–º collect status
                    â”‚
                    â””â”€â–º return {
                        'sports-data': {'status': 'healthy', 'response_time_ms': 45},
                        'air-quality': {'status': 'healthy', 'response_time_ms': 52},
                        'carbon-intensity': {'status': 'degraded', 'response_time_ms': 320},
                        'electricity-pricing': {'status': 'healthy', 'response_time_ms': 38},
                        'smart-meter': {'status': 'healthy', 'response_time_ms': 23},
                        'calendar': {'status': 'healthy', 'response_time_ms': 89}
                    }
```

**Dashboard Display**: Data Sources tab shows real-time status of all external services with color-coded indicators (green/yellow/red).

---

## ğŸš€ Optimization Strategies

### Current Optimizations

1. **Team-Based Filtering** (Sports Data)
   - Only fetch games for user's selected teams
   - Reduces API calls by 85%
   - Improves response time

2. **Aggressive Caching** (All Services)
   - Pattern A: Cache as API failure fallback
   - Pattern B: Cache to reduce external API calls
   - Significantly reduces latency

3. **Batch Writes** (Pattern A Services)
   - Single InfluxDB write per fetch cycle
   - Circuit-level data written in single transaction
   - Reduces database load

4. **Connection Pooling** (All Services)
   - Reuse aiohttp ClientSession across requests
   - InfluxDB client connection persistence
   - Lower connection overhead

5. **Async/Await** (All Services)
   - Non-blocking I/O for external API calls
   - Concurrent health checks
   - Better resource utilization

### Future Optimization Opportunities

1. **Redis Cache Layer**
   - Shared cache across service instances
   - Persistent cache across restarts
   - Pub/sub for cache invalidation

2. **GraphQL Gateway**
   - Replace multiple REST calls with single GraphQL query
   - Client specifies exact data needed
   - Reduced over-fetching

3. **API Response Compression**
   - Enable gzip compression for large responses
   - Reduce network bandwidth usage
   - Faster response times

4. **Webhook Integration**
   - Push notifications from external APIs (if supported)
   - Eliminate polling overhead
   - Real-time updates without constant checking

5. **Service Mesh** (Future Scale)
   - Istio or Linkerd for inter-service communication
   - Circuit breakers and retry policies
   - Distributed tracing

---

## ğŸ› Troubleshooting Guide

### Common Issues & Solutions

#### Issue: Service shows "degraded" status

**Debug Steps**:

1. Check service health endpoint directly:
   ```bash
   curl http://localhost:8012/health
   ```

2. Look for authentication issues:
   ```bash
   # Check logs for "401 Unauthorized" or "403 Forbidden"
   docker logs air-quality-service | grep -i "auth"
   ```

3. Verify environment variables:
   ```bash
   docker exec air-quality-service env | grep API_KEY
   ```

4. Test external API directly:
   ```bash
   curl "https://www.airnowapi.org/aq/observation/latLong/current/?latitude=36.1699&longitude=-115.1398&format=application/json&API_KEY=YOUR_KEY"
   ```

---

#### Issue: No data appearing in dashboard

**Debug Steps**:

1. Check if service is writing to InfluxDB:
   ```bash
   docker logs air-quality-service | grep "written to InfluxDB"
   ```

2. Query InfluxDB directly:
   ```flux
   from(bucket: "events")
     |> range(start: -1h)
     |> filter(fn: (r) => r._measurement == "air_quality")
     |> count()
   ```

3. Check admin-api can query InfluxDB:
   ```bash
   curl http://localhost:8003/api/data-sources/air-quality
   ```

4. Verify dashboard is making requests:
   ```bash
   # Check browser DevTools Network tab
   # Look for failed /api/data-sources/* requests
   ```

---

#### Issue: High external API usage

**Debug Steps**:

1. Check API call counters (Sports Data):
   ```bash
   curl http://localhost:8005/api/v1/metrics/api-usage
   ```

2. Review cache hit rate:
   ```bash
   curl http://localhost:8005/api/v1/cache/stats
   ```

3. Verify TTL settings:
   ```bash
   docker logs sports-data | grep "Cache TTL"
   ```

4. **Solution**: Increase cache TTL or reduce dashboard polling frequency

---

#### Issue: Stale data in dashboard

**Possible Causes**:
- Service fetch interval too long
- Cache TTL too high
- External API returning stale data
- InfluxDB query range incorrect

**Debug Steps**:

1. Check last successful fetch:
   ```bash
   curl http://localhost:8012/health | jq '.metrics.last_successful_fetch'
   ```

2. Verify fetch interval:
   ```bash
   docker exec air-quality-service env | grep FETCH_INTERVAL
   ```

3. Check cache expiration:
   ```python
   # In service logs, look for:
   logger.info(f"Cache age: {(now - last_fetch_time).total_seconds()}s")
   ```

4. **Solution**: Adjust fetch interval or cache TTL based on data volatility

---

## ğŸ“ Change Log

### Version 1.0 (2025-10-13)
**Initial Release**:
- Complete documentation for all 6 external API services
- Detailed call trees for both Pattern A (Push) and Pattern B (Pull)
- Service-specific implementations and data flows
- Caching strategies and optimization patterns
- Performance characteristics and monitoring guidelines
- Troubleshooting guide with debug steps
- Mermaid sequence diagrams and ASCII architecture diagrams
- Quick reference tables and service catalog
- Error handling patterns and recovery strategies

---

## ğŸ“‹ Document Maintenance

**Update this document when**:
- New external API services are added
- Service patterns or architectures change
- External API providers change (e.g., switch from WattTime to different carbon API)
- Caching strategies are modified
- Performance characteristics significantly change
- New optimization techniques are implemented
- Dashboard integration patterns change

**Review Schedule**:
- After adding/modifying any external API service
- When external API rate limits or pricing changes
- Quarterly performance review
- When troubleshooting patterns emerge

**Maintenance Checklist**:
- [ ] Verify all file paths are current
- [ ] Update performance metrics if benchmarks change
- [ ] Check all API endpoint URLs are correct
- [ ] Update service ports if changed
- [ ] Verify external API documentation links
- [ ] Test all troubleshooting steps
- [ ] Update sequence diagrams if flow changes
- [ ] Add entry to Change Log
- [ ] Increment version number
- [ ] Update cross-references to related docs

---

## ğŸ”— Integration with Core System

### Relationship to HA Event Flow

External API services are **complementary** to the core Home Assistant event flow:

- **HA Event Flow** ([HA_EVENT_CALL_TREE.md](./HA_EVENT_CALL_TREE.md)): 
  - High-volume push from Home Assistant (10,000+ events/sec)
  - Real-time state changes
  - Device and entity management

- **External API Services** (this document):
  - Low-volume pull from external sources (1-288 fetches/day)
  - Contextual enrichment data
  - Third-party integrations

**Combined Value**: External services enrich HA events with contextual data (weather, energy prices, occupancy) to enable intelligent automation decisions.

### Data Flow Integration

```
Home Assistant Events â†’ WebSocket Ingestion â†’ InfluxDB
                                                   â†‘
External APIs â†’ External Services â†’ InfluxDB â”€â”€â”€â”€â”€â”˜
                                                   â†“
                              Admin API â† Dashboard queries both data sources
```

**Example Use Case**:
1. **HA Event**: Thermostat temperature change event (from core flow)
2. **External Data**: Current electricity pricing (from this flow)
3. **Smart Decision**: If price > peak threshold, reduce HVAC setpoint by 2Â°F
4. **Result**: Cost-optimized comfort automation

---

**Document maintained by**: BMad Master  
**Questions or updates**: Create issue or update directly following maintenance checklist

